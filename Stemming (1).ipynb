{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3927be50-b3b5-4b51-b741-2c631760c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'jump', 'easili', 'quickli', 'beauti']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Sample text\n",
    "text = \"running jumped easily quickly beautifully\"\n",
    "\n",
    "# Tokenize with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Apply stemming\n",
    "stemmed_words = [stemmer.stem(token.text) for token in doc]\n",
    "\n",
    "print(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2415a507-c3a4-4bd2-9222-4044547f35d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'jump', 'easili', 'quick', 'beauti']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize Snowball Stemmer for English\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Sample text\n",
    "text = \"running jumped easily quickly beautifully\"\n",
    "\n",
    "# Tokenize with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Apply Snowball Stemming\n",
    "stemmed_words = [stemmer.stem(token.text) for token in doc]\n",
    "\n",
    "print(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e411620e-176d-4f8c-86da-f7a508085586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'jump', 'easy', 'quick', 'beauty', 'happy']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "# Initialize Lancaster Stemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# Sample words\n",
    "words = [\"running\", \"jumper\", \"easily\", \"quickly\", \"beautiful\", \"happiness\"]\n",
    "\n",
    "# Apply stemming\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "print(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc7b2218-539d-4f16-986a-9ae8d12decf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'jump', 'easili', 'gener', 'nation', 'studi']\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "words = [\"running\", \"jumps\", \"easily\", \"generous\", \"nationalization\", \"studies\"]\n",
    "\n",
    "stems = [stemmer.stem(word) for word in words]\n",
    "print(stems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fb085de-96d4-4cef-ac98-ce33094d1435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'jump', 'easy', 'gen', 'nat', 'study']\n"
     ]
    }
   ],
   "source": [
    "#Lancaster Stemmer\n",
    "import spacy\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster=LancasterStemmer()\n",
    "stems=[lancaster.stem(word) for word in words]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6d2edae-392a-4195-808a-66227cf6f928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'jump', 'easili', 'generous', 'nation', 'studi']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball=SnowballStemmer(\"english\")\n",
    "stems=[snowball.stem(word)for word in words]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c181a4d-e8f6-4c60-b35b-c6874948df97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Review  \\\n",
      "0     The cats were running in the garden.   \n",
      "1  She enjoys reading books on technology.   \n",
      "2     He quickly jumped over the lazy dog.   \n",
      "\n",
      "                        Stemmed_Review  \n",
      "0     the cat were run in the garden .  \n",
      "1   she enjoy read book on technolog .  \n",
      "2  he quickli jump over the lazi dog .  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Diyanjali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "data = {'Review': [\"The cats were running in the garden.\",\n",
    "                   \"She enjoys reading books on technology.\",\n",
    "                   \"He quickly jumped over the lazy dog.\"]}\n",
    "df = pd.DataFrame(data)\n",
    "stemmer = PorterStemmer()\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "df[\"Stemmed_Review\"] = df[\"Review\"].apply(stem_text)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12db9b49-559a-4d50-8064-a142bef6aec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Headline  \\\n",
      "0        Government is planning new economic reforms   \n",
      "1    Sports team wins the international championship   \n",
      "2  Technology companies are developing AI-based t...   \n",
      "3           Stock market sees a significant increase   \n",
      "4          Scientists discover a new species of fish   \n",
      "\n",
      "                            Stemmed_Headline  \n",
      "0           govern is plan new econom reform  \n",
      "1     sport team win the intern championship  \n",
      "2  technolog compani are develop ai-bas tool  \n",
      "3        stock market see a signific increas  \n",
      "4       scientist discov a new speci of fish  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Diyanjali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample dataset (News Headlines)\n",
    "data = {'Headline': [\n",
    "    \"Government is planning new economic reforms\",\n",
    "    \"Sports team wins the international championship\",\n",
    "    \"Technology companies are developing AI-based tools\",\n",
    "    \"Stock market sees a significant increase\",\n",
    "    \"Scientists discover a new species of fish\"\n",
    "]}\n",
    "df = pd.DataFrame(data)\n",
    "stemmer = PorterStemmer()\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "df[\"Stemmed_Headline\"] = df[\"Headline\"].apply(stem_text)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26896c-a2c2-4246-906f-fdfb3957f227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
